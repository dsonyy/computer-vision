{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import ipywidgets\n",
    "from IPython.display import clear_output\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 1280\n",
    "HEIGHT = 1024\n",
    "SIZE = (WIDTH, HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import IPython.display\n",
    "import ipywidgets\n",
    "\n",
    "INTERFACE = \"usb\" # usb, csi\n",
    "\n",
    "def get_source(id, interface=INTERFACE):\n",
    "    if id == \"left\":\n",
    "        id = 0\n",
    "    elif id == \"right\":\n",
    "        id = 1\n",
    "\n",
    "    if interface == \"usb\":\n",
    "        return id\n",
    "    elif interface == \"csi\":\n",
    "        return (\n",
    "            \"nvarguscamerasrc sensor-id=%d sensor-mode=%d ! \"\n",
    "            \"video/x-raw(memory:NVMM), \"\n",
    "            \"width=(int)%d, height=(int)%d, \"\n",
    "            \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
    "            \"nvvidconv flip-method=%d ! \"\n",
    "            \"video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! \"\n",
    "            \"videoconvert ! \"\n",
    "            \"video/x-raw, format=(string)BGR ! appsink\"\n",
    "            % (\n",
    "                id, # camera id\n",
    "                3, # mode\n",
    "                640, # width\n",
    "                480, # height\n",
    "                10, # frame rate\n",
    "                0, # flip method\n",
    "                640, # display width\n",
    "                480, # display height\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Unknown camera source.\")\n",
    "\n",
    "def camera_capture(id):\n",
    "    camera = cv.VideoCapture(get_source(id))\n",
    "    camera.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    camera.set(cv.CAP_PROP_FRAME_HEIGHT, 1024)\n",
    "    ret, image = camera.read()\n",
    "\n",
    "    if not ret:\n",
    "        return None\n",
    "\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    camera.release()\n",
    "    return image\n",
    "\n",
    "def camera_capture2():\n",
    "    left = cv.VideoCapture(get_source(\"left\"))\n",
    "    left.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    left.set(cv.CAP_PROP_FRAME_HEIGHT, 1024)\n",
    "\n",
    "    right = cv.VideoCapture(get_source(\"right\"))\n",
    "    right.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    right.set(cv.CAP_PROP_FRAME_HEIGHT, 1024)\n",
    "\n",
    "    if not (left.grab() and right.grab()):\n",
    "        return None\n",
    "\n",
    "    _, left_frame = left.retrieve()\n",
    "    _, right_frame = right.retrieve()\n",
    "\n",
    "    left_frame = cv.cvtColor(left_frame, cv.COLOR_BGR2GRAY)\n",
    "    right_frame = cv.cvtColor(right_frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    left.release()\n",
    "    right.release()\n",
    "    return np.hstack((left_frame, right_frame))\n",
    "\n",
    "def camera_stream(id):\n",
    "    camera = cv.VideoCapture(get_source(id))\n",
    "    camera.set(3, 1280)\n",
    "    camera.set(4, 1024)\n",
    "    try: \n",
    "        while True:\n",
    "            ret, frame = camera.read()\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            frame = cv.rotate(frame, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "            stream = BytesIO()\n",
    "            Image.fromarray(frame).save(stream, format=\"jpeg\")\n",
    "            IPython.display.display(IPython.display.Image(data=stream.getvalue()))\n",
    "\n",
    "            IPython.display.clear_output(wait=True)\n",
    "    except KeyboardInterrupt:\n",
    "        camera.release()\n",
    "        print(\"Stream Stopped\")\n",
    "\n",
    "running = True\n",
    "camera_widget = ipywidgets.Image(width=1200)\n",
    "def camera_stream2():\n",
    "    global running\n",
    "    camera0 = cv.VideoCapture(get_source(0))\n",
    "    camera0.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    camera0.set(cv.CAP_PROP_FRAME_HEIGHT, 1024)\n",
    "\n",
    "    camera1 = cv.VideoCapture(get_source(1))\n",
    "    camera1.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    camera1.set(cv.CAP_PROP_FRAME_HEIGHT, 1024)\n",
    "    try: \n",
    "        while running:\n",
    "            camera0.grab()\n",
    "            camera1.grab()\n",
    "\n",
    "            _, frame0 = camera0.retrieve()\n",
    "            _, frame1 = camera1.retrieve()\n",
    "\n",
    "            frame0 = cv.cvtColor(frame0, cv.COLOR_BGR2GRAY)\n",
    "            frame1 = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "            frame = np.hstack((frame0, frame1))\n",
    "            \n",
    "            # frame = cv.flip(frame, 1)\n",
    "    \n",
    "            stream = BytesIO()\n",
    "            Image.fromarray(frame).save(stream, format=\"jpeg\")\n",
    "            camera_widget.value = stream.getvalue()\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    camera0.release()\n",
    "    camera1.release()\n",
    "    print(\"Stream Stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream Stopped\n"
     ]
    }
   ],
   "source": [
    "running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ed9aec707f4aa885884ba795ab72bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'', width='600'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "running = True\n",
    "\n",
    "camera_widget = ipywidgets.Image(width=600)\n",
    "all_widgets = ipywidgets.VBox((\n",
    "    camera_widget, \n",
    "))\n",
    "\n",
    "def live_execution():\n",
    "    global camera_widget\n",
    "    display(all_widgets)\n",
    "\n",
    "    global running\n",
    "    camera0 = cv.VideoCapture(get_source(0))\n",
    "    camera0.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    camera0.set(cv.CAP_PROP_FRAME_HEIGHT, 1024)\n",
    "\n",
    "    camera1 = cv.VideoCapture(get_source(1))\n",
    "    camera1.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    camera1.set(cv.CAP_PROP_FRAME_HEIGHT, 1024)\n",
    "    try: \n",
    "        while running:\n",
    "            camera0.grab()\n",
    "            camera1.grab()\n",
    "\n",
    "            _, frame0 = camera0.retrieve()\n",
    "            _, frame1 = camera1.retrieve()\n",
    "\n",
    "            frame0 = cv.cvtColor(frame0, cv.COLOR_BGR2GRAY)\n",
    "            frame1 = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "            frame = np.hstack((frame0, frame1))\n",
    "\n",
    "            stream = BytesIO()\n",
    "            Image.fromarray(np.uint8(frame)).save(stream, format=\"jpeg\")\n",
    "            camera_widget.value = stream.getvalue()\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    print(\"Stream Stopped\")\n",
    "    camera0.release()\n",
    "    camera1.release()\n",
    "\n",
    "thread = threading.Thread(target=live_execution)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_images():\n",
    "    left = camera_capture(get_source(\"left\"))\n",
    "    right = camera_capture(get_source(\"right\"))\n",
    "\n",
    "    count = len(os.listdir(\"calibration/left\"))\n",
    "    Image.fromarray(left).save(\"calibration/left/\" + str(count) + \".jpg\")\n",
    "\n",
    "    count = len(os.listdir(\"calibration/right\"))\n",
    "    Image.fromarray(right).save(\"calibration/right/\" + str(count) + \".jpg\")\n",
    "\n",
    "    display(Image.fromarray(np.hstack((left, right))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 * 2 images.\n"
     ]
    }
   ],
   "source": [
    "left_images = []\n",
    "right_images = []\n",
    "\n",
    "for f in os.listdir(\"calibration/left\"):\n",
    "    image = cv.imread(\"calibration/left/\" + f)\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    left_images.append(image)\n",
    "\n",
    "for f in os.listdir(\"calibration/right\"):\n",
    "    image = cv.imread(\"calibration/right/\" + f)\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    right_images.append(image)\n",
    "\n",
    "if len(left_images) == len(right_images):\n",
    "    images_num = len(left_images)\n",
    "    print(\"Loaded\", images_num, \"* 2 images.\")\n",
    "else:\n",
    "    print(\"The number of right and left images are different!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding chessboard corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair 0: OK\n",
      "Processing pair 1: OK\n",
      "Processing pair 2: OK\n",
      "Processing pair 3: OK\n",
      "Processing pair 4: ERROR\n",
      "Processing pair 5: OK\n",
      "Processing pair 6: ERROR\n",
      "Processing pair 7: OK\n",
      "Processing pair 8: OK\n",
      "Processing pair 9: OK\n",
      "Processing pair 10: OK\n",
      "Processing pair 11: ERROR\n",
      "Processing pair 12: OK\n",
      "Processing pair 13: OK\n",
      "Processing pair 14: OK\n",
      "Processing pair 15: OK\n"
     ]
    }
   ],
   "source": [
    "CRITERIA = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "obj_points = []\n",
    "left_image_points = []\n",
    "right_image_points = []\n",
    "\n",
    "for idx, (left_image, right_image) in enumerate(zip(left_images, right_images)):\n",
    "    print(\"Processing pair\", idx, end=\": \")\n",
    "    \n",
    "    # Find chessboard corners\n",
    "    ret_left, corners_left = cv.findChessboardCorners(left_image, (7, 7), cv.CALIB_CB_FAST_CHECK)\n",
    "    ret_right, corners_right = cv.findChessboardCorners(right_image, (7, 7), cv.CALIB_CB_FAST_CHECK)\n",
    "\n",
    "    # If no corners found, continue\n",
    "    if not (ret_left and ret_right):\n",
    "        print(\"ERROR\")\n",
    "        continue\n",
    "\n",
    "    # Increase the accuracy of corner points\n",
    "    corners_left = cv.cornerSubPix(left_image, corners_left, (11, 11), (-1, -1), CRITERIA)\n",
    "    corners_right = cv.cornerSubPix(right_image, corners_right, (11, 11), (-1, -1), CRITERIA)\n",
    "    \n",
    "    # Save chessboard with drawn corners\n",
    "    left_image_corners = left_image.copy()\n",
    "    left_image_corners = cv.cvtColor(left_image_corners, cv.COLOR_GRAY2BGR)\n",
    "    cv.drawChessboardCorners(left_image_corners, (7, 7), corners_left, True)\n",
    "    cv.imwrite(\"calibration-corners/left/\" + str(idx) + \".png\", left_image_corners)\n",
    "    right_image_corners = right_image.copy()\n",
    "    right_image_corners = cv.cvtColor(right_image_corners, cv.COLOR_GRAY2BGR)\n",
    "    cv.drawChessboardCorners(right_image_corners, (7, 7), corners_right, True)\n",
    "    cv.imwrite(\"calibration-corners/right/\" + str(idx) + \".png\", right_image_corners)\n",
    "\n",
    "    # Add chessboard points as object points\n",
    "    obj = np.zeros((7 * 7, 3), np.float32)\n",
    "    obj[:, :2] = np.mgrid[0:7, 0:7].T.reshape(-1, 2)\n",
    "    obj_points.append(obj)\n",
    "\n",
    "    # Add chessboard points as image points\n",
    "    left_image_points.append(corners_left)\n",
    "    right_image_points.append(corners_right)\n",
    "     \n",
    "    print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating distortions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating left camera...\n",
      "Matrix:\n",
      "  1093.231\t     0.000\t   670.008\n",
      "     0.000\t  1105.950\t   577.428\n",
      "     0.000\t     0.000\t     1.000\n",
      "Calibrating right camera...\n",
      "Matrix:\n",
      "  1077.832\t     0.000\t   641.361\n",
      "     0.000\t  1092.302\t   583.397\n",
      "     0.000\t     0.000\t     1.000\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "print(\"Calibrating left camera...\")\n",
    "_, left_matrix, left_distortion_coeff, left_rotation_vec, left_translation_vec = cv.calibrateCamera(\n",
    "    obj_points, \n",
    "    left_image_points,\n",
    "    SIZE, None, None\n",
    ")\n",
    "print(\"Matrix:\")\n",
    "print(\"{:10.3f}\\t{:10.3f}\\t{:10.3f}\".format(left_matrix[0,0], left_matrix[0,1], left_matrix[0,2]))\n",
    "print(\"{:10.3f}\\t{:10.3f}\\t{:10.3f}\".format(left_matrix[1,0], left_matrix[1,1], left_matrix[1,2]))\n",
    "print(\"{:10.3f}\\t{:10.3f}\\t{:10.3f}\".format(left_matrix[2,0], left_matrix[2,1], left_matrix[2,2]))\n",
    "\n",
    "print(\"Calibrating right camera...\")\n",
    "_, right_matrix, right_distortion_coeff, _, _ = cv.calibrateCamera(\n",
    "    obj_points, \n",
    "    right_image_points,\n",
    "    SIZE, None, None\n",
    ")\n",
    "print(\"Matrix:\")\n",
    "print(\"{:10.3f}\\t{:10.3f}\\t{:10.3f}\".format(right_matrix[0,0], right_matrix[0,1], right_matrix[0,2]))\n",
    "print(\"{:10.3f}\\t{:10.3f}\\t{:10.3f}\".format(right_matrix[1,0], right_matrix[1,1], right_matrix[1,2]))\n",
    "print(\"{:10.3f}\\t{:10.3f}\\t{:10.3f}\".format(right_matrix[2,0], right_matrix[2,1], right_matrix[2,2]))\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image undistortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_left_matrix, left_roi = cv.getOptimalNewCameraMatrix(left_matrix, left_distortion_coeff, SIZE, 1, SIZE)\n",
    "new_right_matrix, right_roi = cv.getOptimalNewCameraMatrix(right_matrix, right_distortion_coeff, SIZE, 1, SIZE)\n",
    "\n",
    "for f in os.listdir(\"calibration/left\"):\n",
    "    image = cv.imread(\"calibration/left/\" + f)\n",
    "    image = cv.undistort(image, left_matrix, left_distortion_coeff, None, new_left_matrix)\n",
    "    cv.imwrite(\"calibrate-undistort/left/\" + f, image)\n",
    "    x, y, w, h = left_roi\n",
    "    cv.imwrite(\"calibrate-undistort-crop/left/\" + f, image[y:y + h, x:x + w])\n",
    "    \n",
    "for f in os.listdir(\"calibration/right\"):\n",
    "    image = cv.imread(\"calibration/right/\" + f)\n",
    "    image = cv.undistort(image, right_matrix, right_distortion_coeff, None, new_right_matrix)\n",
    "    cv.imwrite(\"calibrate-undistort/right/\" + f, image)\n",
    "    x, y, w, h = right_roi\n",
    "    cv.imwrite(\"calibrate-undistort-crop/right/\" + f, image[y:y + h, x:x + w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating cameras together...\n"
     ]
    }
   ],
   "source": [
    "print(\"Calibrating cameras together...\")\n",
    "_, _, _, _, _, rotation_matrix, translation_vector, R, T = cv.stereoCalibrate(\n",
    "    obj_points,\n",
    "    left_image_points, right_image_points,\n",
    "    left_matrix, left_distortion_coeff,\n",
    "    right_matrix, right_distortion_coeff,\n",
    "    (1280, 1024), None, None, None, None,\n",
    "    cv.CALIB_FIX_INTRINSIC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectifying cameras...\n"
     ]
    }
   ],
   "source": [
    "print(\"Rectifying cameras...\")\n",
    "left_rectification, right_rectification, left_projection, right_projection, _, left_roi, right_roi = cv.stereoRectify(\n",
    "    left_matrix, left_distortion_coeff,\n",
    "    right_matrix, right_distortion_coeff,\n",
    "    (1280, 1024), rotation_matrix, translation_vector,\n",
    "    R, T, None, None, None,\n",
    "    cv.CALIB_ZERO_DISPARITY, 0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_max_x, left_map_y = cv.initUndistortRectifyMap(\n",
    "    left_matrix, left_distortion_coeff, left_rectification,\n",
    "    left_projection, (1280, 1024), cv.CV_32FC1\n",
    ")\n",
    "\n",
    "right_max_x, right_map_y = cv.initUndistortRectifyMap(\n",
    "    right_matrix, right_distortion_coeff, right_rectification,\n",
    "    right_projection, (1280, 1024), cv.CV_32FC1\n",
    ")\n",
    "\n",
    "np.savez_compressed(\"stereo-12cm.npz\", \n",
    "    left_max_x=left_max_x, left_map_y=left_map_y, left_roi=left_roi,\n",
    "    right_max_x=right_max_x, right_map_y=right_map_y, right_roi=right_roi\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = np.load(\"stereo-12cm.npz\", allow_pickle=False)\n",
    "left_max_x = calibration[\"left_max_x\"]\n",
    "left_map_y = calibration[\"left_map_y\"]\n",
    "left_roi = tuple(calibration[\"left_roi\"])\n",
    "right_max_x = calibration[\"right_max_x\"]\n",
    "right_map_y = calibration[\"right_map_y\"]\n",
    "right_roi = tuple(calibration[\"right_roi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth(left, right):\n",
    "    stereo = cv.StereoBM_create()\n",
    "    stereo.setMinDisparity(4)\n",
    "    stereo.setNumDisparities(3 * 16)\n",
    "    stereo.setBlockSize(11)\n",
    "    stereo.setROI1(left_roi)\n",
    "    stereo.setROI2(right_roi)\n",
    "    stereo.setSpeckleRange(16)\n",
    "    stereo.setSpeckleWindowSize(45)\n",
    "\n",
    "    left = cv.cvtColor(left, cv.COLOR_BGR2GRAY)\n",
    "    right = cv.cvtColor(right, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    fixed_left = cv.remap(left, left_max_x, left_map_y, cv.INTER_LINEAR)\n",
    "    fixed_right = cv.remap(right, right_max_x, right_map_y, cv.INTER_LINEAR)\n",
    "\n",
    "    depth = stereo.compute(fixed_left, fixed_right)\n",
    "\n",
    "    lower, upper = 0, 255\n",
    "    return (lower + (upper - lower) * depth).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_stream():\n",
    "    camera0 = cv.VideoCapture(get_source(0))\n",
    "    camera0.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    camera0.set(cv.CAP_PROP_FRAME_HEIGHT, 1024)\n",
    "\n",
    "    camera1 = cv.VideoCapture(get_source(1))\n",
    "    camera1.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    camera1.set(cv.CAP_PROP_FRAME_HEIGHT, 1024)\n",
    "    try: \n",
    "        while True:\n",
    "            camera0.grab()\n",
    "            camera1.grab()\n",
    "\n",
    "            _, frame0 = camera0.retrieve()\n",
    "            _, frame1 = camera1.retrieve()\n",
    "            \n",
    "            depth = get_depth(frame0, frame1)\n",
    "            \n",
    "            frame0 = cv.cvtColor(frame0, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            frame = np.hstack((depth, frame0))\n",
    "\n",
    "            # frame = cv.flip(frame, 1)\n",
    "\n",
    "            stream = BytesIO()\n",
    "            PIL.Image.fromarray(frame).save(stream, format=\"jpeg\")\n",
    "    \n",
    "            IPython.display.display(IPython.display.Image(data=stream.getvalue()))\n",
    "            IPython.display.clear_output(wait=True)\n",
    "    except KeyboardInterrupt:\n",
    "        camera0.release()\n",
    "        camera1.release()\n",
    "        print(\"Stream Stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream Stopped\n"
     ]
    }
   ],
   "source": [
    "depth_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, image in enumerate(images):\n",
    "    image_undist = cv.undistort(image, matrix, distortion_coeff, None, new_camera_matrix)\n",
    "    Image.fromarray(image_undist).save(os.path.join(\"calibration-undistorted\", str(idx) + \".jpg\"))\n",
    "\n",
    "    x, y, w, h = roi\n",
    "    image_undist_roi = image_undist[y:y + h, x:x + w]\n",
    "    Image.fromarray(image_undist_roi).save(os.path.join(\"calibration-undistorted-roi\", str(idx) + \".jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating re-projection error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_error = 0\n",
    "for i in range(len(obj_points)):\n",
    "    img_points2, _ = cv.projectPoints(obj_points[i], rotation_vec[i], translation_vec[i], matrix, distortion_coeff)\n",
    "    mean_error += cv.norm(img_points[i], img_points2, cv.NORM_L2) / len(img_points2)\n",
    "\n",
    "print(\"Total error:\", mean_error / len(obj_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez(\"logitech-500.npz\", \n",
    "    matrix=matrix,\n",
    "    distortion_coeff=distortion_coeff,\n",
    "    rotation_vec=rotation_vec,\n",
    "    translation_vec=translation_vec,\n",
    "    new_camera_matrix=new_camera_matrix,\n",
    "    roi=roi)\n",
    "\n",
    "coefficients = dict(np.load(\"logitech-500.npz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = dict(np.load(\"logitech-500.npz\"))\n",
    "matrix, distortion_coeff = coefficients[\"matrix\"], coefficients[\"distortion_coeff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, corners, imgpts):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    img = cv.line(img, corner, tuple(imgpts[0].ravel()), (255,0,0), 5)\n",
    "    img = cv.line(img, corner, tuple(imgpts[1].ravel()), (0,255,0), 5)\n",
    "    img = cv.line(img, corner, tuple(imgpts[2].ravel()), (0,0,255), 5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "camera = cv.VideoCapture(get_source(0))\n",
    "camera.set(3, 640)\n",
    "camera.set(4, 480)\n",
    "try: \n",
    "    while True:\n",
    "        obj_points = []\n",
    "        img_points = []\n",
    "\n",
    "        ret, frame = camera.read()\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        frame = cv.rotate(frame, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        ret, corners = cv.findChessboardCorners(frame, (7,7), None)\n",
    "        if ret:\n",
    "            obj = np.zeros((7 * 7, 3), np.float32)\n",
    "            obj[:, :2] = np.mgrid[0:7, 0:7].T.reshape(-1, 2)\n",
    "            obj_points.append(obj)\n",
    "            ret, rvecs, tvecs = cv.solvePnP(obj, corners, matrix, distortion_coeff)\n",
    "\n",
    "            axis = np.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)\n",
    "            img_points, jac = cv.projectPoints(axis, rvecs, tvecs, matrix, distortion_coeff)\n",
    "\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_GRAY2RGB)\n",
    "            frame = draw(frame, corners, img_points)\n",
    "\n",
    "        stream = BytesIO()\n",
    "        PIL.Image.fromarray(frame).save(stream, format=\"jpeg\")\n",
    "        IPython.display.display(IPython.display.Image(data=stream.getvalue()))\n",
    "\n",
    "        IPython.display.clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    camera.release()\n",
    "    print(\"Stream Stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_LEFT = 0\n",
    "ID_RIGHT = 1\n",
    "\n",
    "# left, right = camera_capture(ID_LEFT), camera_capture(ID_RIGHT)\n",
    "left, right = cv.imread(\"left.jpg\"), cv.imread(\"right.jpg\")\n",
    "left, right = cv.cvtColor(left, cv.COLOR_BGR2GRAY), cv.cvtColor(right, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "stereo = cv.StereoBM_create(numDisparities=16, blockSize=5)\n",
    "disparity = stereo.compute(left, right)\n",
    "\n",
    "plt.subplots(figsize=(20, 20))\n",
    "plt.imshow(disparity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = cv.rotate(camera_capture(0), cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "Image.fromarray(left).save(\"left.jpg\")\n",
    "display(Image.fromarray(left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = cv.rotate(camera_capture(0), cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "Image.fromarray(right).save(\"right.jpg\")\n",
    "display(Image.fromarray(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = dict(np.load(\"logitech-500.npz\"))\n",
    "matrix, distortion_coeff, new_camera_matrix = coefficients[\"matrix\"], coefficients[\"distortion_coeff\"], coefficients[\"new_camera_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_undist = cv.undistort(left, matrix, distortion_coeff, None, new_camera_matrix)\n",
    "\n",
    "x, y, w, h = roi\n",
    "left_undist = left_undist[y:y + h, x:x + w]\n",
    "\n",
    "display(Image.fromarray(left_undist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_undist = cv.undistort(right, matrix, distortion_coeff, None, new_camera_matrix)\n",
    "\n",
    "x, y, w, h = roi\n",
    "right_undist = right_undist[y:y + h, x:x + w]\n",
    "\n",
    "display(Image.fromarray(right_undist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo = cv.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "disparity = stereo.compute(left, right)\n",
    "\n",
    "plt.subplots(figsize=(20, 20))\n",
    "plt.imshow(disparity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
